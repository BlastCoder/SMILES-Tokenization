{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trie.py\n",
    "# Build a TTG-guided token-replacement trie for the PubChem-100 K slice.\n",
    "\n",
    "import time\n",
    "from utils import iter_smiles\n",
    "import trie_funcs as tf\n",
    "\n",
    "SLICE = \"data/pubchem_100K.parquet\"\n",
    "OUT_DIR = \"ttg_vocab\"            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trie_metrics(smiles_list, tokenizer):\n",
    "    \"\"\"\n",
    "    Compute all Trie metrics (fertility, mean, variance, normalized entropy) in a single pass.\n",
    "    \n",
    "    Args:\n",
    "        smiles_list: Path to parquet file containing SMILES strings\n",
    "        tokenizer: Trie tokenizer state with compress_and_len function\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (fertility, mean, variance, normalized_entropy)\n",
    "    \"\"\"\n",
    "    from utils import iter_smiles\n",
    "    from collections import Counter\n",
    "    import tqdm\n",
    "    import math\n",
    "    \n",
    "    # Import trie_funcs locally to avoid import issues\n",
    "    try:\n",
    "        import trie_funcs as tf\n",
    "    except ImportError:\n",
    "        raise ImportError(\"trie_funcs module is required for Trie metrics\")\n",
    "    \n",
    "    total_tokens = 0\n",
    "    total_chars = 0\n",
    "    token_counts = []\n",
    "    token_freq = Counter()\n",
    "    \n",
    "    # Single pass through the data\n",
    "    for smi in tqdm.tqdm(iter_smiles(smiles_list), desc=\"Trie metrics\"):\n",
    "        # Tokenize once per SMILES\n",
    "        base = tf.tokenize(smi)  # list of atomic tokens\n",
    "        tokens = tf.compress(base, tokenizer.replace_root)\n",
    "        token_count = len(tokens)\n",
    "        \n",
    "        # Collect data for all metrics\n",
    "        total_tokens += token_count\n",
    "        total_chars += len(smi)\n",
    "        token_counts.append(token_count)\n",
    "        token_freq.update(tokens)  # For entropy calculation\n",
    "    \n",
    "    n = len(token_counts)\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    fertility = total_tokens / total_chars if total_chars > 0 else 0\n",
    "    trie_avg = total_tokens / n if n > 0 else 0\n",
    "    trie_var = sum((count - trie_avg) ** 2 for count in token_counts) / n if n > 0 else 0\n",
    "    \n",
    "    # Calculate normalized entropy\n",
    "    if total_tokens == 0:\n",
    "        normalized_entropy = 0.0\n",
    "    else:\n",
    "        vocab_size = len(token_freq)\n",
    "        if vocab_size <= 1:\n",
    "            normalized_entropy = 0.0\n",
    "        else:\n",
    "            # Shannon entropy\n",
    "            entropy = -sum((cnt/total_tokens) * math.log2(cnt/total_tokens)\n",
    "                          for cnt in token_freq.values())\n",
    "            # Normalize by log₂(observed_vocab_size)\n",
    "            normalized_entropy = entropy / math.log2(vocab_size)\n",
    "    \n",
    "    return fertility, trie_avg, trie_var, normalized_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_out_name(k: int, freq: int, ent: float) -> str:\n",
    "    \"\"\"\n",
    "    Produce a file name that encodes the hyper-parameters, e.g.\n",
    "    ttg_pubchem100K_K8_F4_H2p0.pkl\n",
    "    (the dot in entropy is replaced by “p” to keep the name shell-safe).\n",
    "    \"\"\"\n",
    "    ent_str = str(ent).replace(\".\", \"p\")\n",
    "    return f\"{OUT_DIR}/ttg_pubchem100K_K{k}_F{freq}_H{ent_str}.pkl\"\n",
    "\n",
    "def run_ttg(k: int = 8, freq_thr: int = 4, entropy_thr: float = 2.0) -> str:\n",
    "    \"\"\"\n",
    "    Build a TTG-guided compressor with the given hyper-parameters.\n",
    "    Returns the path of the saved pickle.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> run_ttg(k=10, freq_thr=3, entropy_thr=1.5)\n",
    "    'ttg_pubchem100K_K10_F3_H1p5.pkl'\n",
    "    \"\"\"\n",
    "    out_path = _make_out_name(k, freq_thr, entropy_thr)\n",
    "\n",
    "    print(f\"Building TTG-guided trie compressor (K={k}, FREQ_THR={freq_thr}, \"\n",
    "          f\"ENTROPY_THR={entropy_thr}) …\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    state = tf.prepare_compressor_with_ttg(\n",
    "        iter_smiles(SLICE),\n",
    "        K=k,\n",
    "        freq_thr=freq_thr,\n",
    "        entropy_thr=entropy_thr,\n",
    "    )\n",
    "\n",
    "    tf.save_state(state, out_path)\n",
    "    print(f\"✔ Trie saved → {out_path}  ({time.time() - t0:.1f}s)\")\n",
    "\n",
    "    trie_fert, trie_avg, trie_var, trie_ent = compute_trie_metrics(SLICE, state)\n",
    "\n",
    "    print(f\"✔ Trie Metrics Computed → {out_path}  ({time.time() - t0:.1f}s)\")\n",
    "\n",
    "    return out_path, trie_fert, trie_avg, trie_var, trie_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TTG-guided trie compressor (K=8, FREQ_THR=4, ENTROPY_THR=2.0) …\n",
      "✔ Trie saved → ttg_vocab/ttg_pubchem100K_K8_F4_H2p0.pkl  (15.2s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trie metrics: 100000it [00:00, 103106.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Trie Metrics Computed → ttg_vocab/ttg_pubchem100K_K8_F4_H2p0.pkl  (16.2s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('ttg_vocab/ttg_pubchem100K_K8_F4_H2p0.pkl',\n",
       " 0.5747782249481419,\n",
       " 25.5174,\n",
       " 203.6626972400091,\n",
       " 0.33564296222247203)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ttg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "davai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
